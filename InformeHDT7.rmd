---
title: "Informe HDT7"
author: "Fredy Velasquez 201011, Pablo Escobar 20936, Angel Higueros 20460"
date: "21/4/2023"
output: html_document
---

{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


# HDT 7: Maquina Vectoriales de Soporte (SVM)

{r message=FALSE, warning=FALSE}
#Importamos las librerias necesarias
library(e1071)
library(caret)
#Leemos el dataset
data<-read.csv('train.csv')
#Cambiamos los nulls por 0
data[is.na(data)] <- 0
#Calculo de percentiles
percentil <- quantile(data$SalePrice)
#Percentiles
estado<-c('Estado')
data$Estado<-estado
#Economica=0
#Intermedia=1
#Cara=2
data <- within(data, Estado[SalePrice<=129975] <- 'Economica')
data$Estado[(data$SalePrice>129975 & data$SalePrice<=163000)] <- 'Intermedia'
data$Estado[data$SalePrice>163000] <- 'Cara'
#Cambio de tipo de columnas, esto es necesario ya que para poder usar svm es necesario contar con datos numericos e indicar que la variable de estado es nuestra variable categorica, esto mediante el metodo as factor.
data$SalePrice<-as.numeric(data$SalePrice)
data$GrLivArea<-as.numeric(data$GrLivArea)
data$GarageCars<-as.numeric(data$GarageCars)
data$LotArea<-as.numeric(data$LotArea)
data$Estado<-as.factor(data$Estado)
#SVM
#Indicamos el porcentaje de entranamiento
porcentaje<-0.7
#Semilla para que el experimento sea repetible
set.seed(123)
#Creamos el dataframe con los valores a los cuales vamos a determinar el valor de las casas
datos<-data.frame(data$SalePrice,data$GrLivArea,data$GarageCars,data$LotArea,data$Estado)
#Datos de entrenamiento y prueba
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
train<-datos[corte,]
test<-datos[-corte,]
#Creamos el modelo
modelosvm<-svm(data.Estado~., data = train, scale = F)




{r}

summary(modelosvm)

Como se observa se creo el modelo correctamente, indicando que poseemos 3 variables categoricas, los cuales son Cara, Intermedia y Economica. Con un kernel radial, siendo este el default. 

{r}

plot(modelosvm,train,data.SalePrice~data.GrLivArea)


Al graficar nuestro modelo, se observa que poseemos mayor variedad de casas establecidas como caras, ademas que la grafica nos logra representar la clasificacion de las casas, recordemos que al ser aprendizaje no supervisado, la maquina no conoce etiquetas claras de los datos, por ello el algoritmo SVM nos permite clasificar las casas dependiendo de argumentos, en este caso como se muestra en la grafica, se evaluo mediante GrLiveArea y SalePrice.

```{r}


#Modelos
modeloSVM_L<-svm(data.Estado~., data=train, cost=0.5, kernel="linear")#95%
modeloSVM_R<-svm(data.Estado~., data=train, gamma=2^-5, kernel="radial")
modeloSVM_R<-svm(data.Estado~., data=train, gamma=2^1, kernel="radial")
#Prediccion
prediccionL<-predict(modeloSVM_L,newdata=test[,1:4])
prediccionR<-predict(modeloSVM_R,newdata=test[,1:4])
#Modelo tuneado
modeloTuneado<-tune.svm(data.Estado~., data=train, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
predMejorModelo<-predict(modeloTuneado$best.model,newdata = test[,1:4])




Se crearon los modelos con distintos C, Kernel y Gammas, con el fin de demostrar la diferencia entre cada uno, cabe mencionar, que tambien se tuneo un modelo, para optimizar el resultado. 

#### Primer modelo
{r}
confusionMatrix(test$data.Estado,prediccionL)

Como se observa este modelo tuvo una C de 0.5 y fue evaluado con un kernel lineal, dando como resultado una prediccion con precision de 0.9795, siendo esta muy alta, y cabe mencionar que como se observa esta no tuvo overfitting, ya que la precision no dio 1. Ademas, solo tuvo 9 casas erroneas, demostrando que fue una buena prediccion. 

#### Segundo Modelo
{R}
confusionMatrix(test$data.Estado,prediccionR)


Este segundo modelo se creo con una gamma de 2^-5 y kernel radial, obteniendo una precision de 0.93, siendo esta mas baja que la anterior, teniendo 29 casas erroneas. Indicando que este modelo no fue el mejor de todos, ademas se observa que tampoco tiene overfitting.

#### Tercer modelo tuneado

{r}
confusionMatrix(test$data.Estado,predMejorModelo)

```

Para este modelo fue necesario tunearlo, esto fue mediante distintos valores de C, el cual atraves de iteracion iba alternando de C encontrando el valor mas optimo, en este caso se uso valores de C de 0.01,0.1,0.5,1,5,10,16,20,32 y con un kernel lineal. Obteniendo como resultado una precision de 0.9841, siendo esta la precision mas alta de los otros dos modelos, esto gracias al tuneo realizado. Y nuevamente como se observa no tiene overfitting ya que el valor devuelto no es 1.

### Comparativa entre los tres modelos: 

Para realizar esta comparativa, haremos mencion de los tres modelos en base a su numero, es decir, los modelos seran denominados de la siguiente manera: 1, 2 y 3. 
Empezamos por el modelo 1, como se puede observar en el la matriz de confusion, tenemos un nivel de acierto de 97%, lo cual podemos decir que es extremadamente bueno, podemos decir que basicamente no tuvo equivocacion, siguiendo con el 2, alli podemos notar un numero mas bajo, estamos hablando de un nivel de acierto del 93%, teniendo un porcentaje de error del 7%, el mas bajo de los modelos que creamos, por ultimo en el modelo 3, logramos tener un nivel de 98%, es el mejor porcentaje que hemos tenido a lo largo de las hojas de trabajo. 


### Comparativa entre el mejor modelo y los metodos pasados: 

El resultado de nuestros metodos pasados, estan de la siguiente manera: 

1. Naive Bayes: 0.93
2. Random Forest: 0.82
3. Arbol de decisión: 0.70

Como podemos observar y tomando en cuenta el valor del modelo tuneado, podemos decir que la eficiencia del ultimo modelo creado en esta hoja de trabajo fue superior a lo metodos pasados, el mas cercano fue el metodo de Naive Bayes, pero si en cuanto a demora nos refererimos, realmente los 4 modelos se toman el mismo tiempo de ejecucion, por lo que el tiempo no es un factor que sea determinante al momento de elegir un modelo.  


### Modelo de regresión usando el precio de la casa:

```{r}

#Regresion lineal
fitLMPW<-lm(data.SalePrice~ ., data = train)
predL<-predict(fitLMPW, newdata = test)
#Verificando la predicci?n
resultados<-data.frame(test$data.SalePrice,predL)
i10a<-head(resultados, n=5)
i10b<-ggplot(data=train,mapping = aes(x=data.SalePrice,y=data.GrLivArea ))+
  geom_point(color='red',size=2)+
  geom_smooth(method = 'lm',se=TRUE,color='black')+
  labs(title = 'Precio de venta ~ Pies cuadrados de vivienda',x="Precio de venta",y='Pies cuadrados de vivienda')+
  theme_bw()+theme(plot.title = element_text(hjust = 0.5))


```

```{r}
i10a
i10b
```

Partiendo de la tabla anterior se concluye que es un buen modelo porque los precios de las casas no se alejan mucho de los precios reales. También la gráfica afirma que la correlación de las variables del modelo es muy buena. Además, gran parte de los datos no está sobre la línea, indicando que no hay overfitting.


### Comparativa del modelo de regresión con los anteriores:

Este último modelo fue más rápido de procesar, sin embargo, no es el mejor para predecir. Esto útimo no quiere decir que es ineficiente o poco efectivo.
